# MwWn-20190424

# Idiomicity Model


## Usage Variation
* insertion
* substitution patterns

## Modeling Compoundness

Morphological graph is aimed to capture the morphological relations between productive relations between Chinese characters (often itself serve as a single character) and words. The graph exclusive includes bi-syllabic words for two considerations: (1) Chinese words are predominantly bi-syllabic, which accounts for **(numbers here)**% word frequnecy in a corpus. (2) The morphological graph constructed in this search is to model how predictive a QIE compound is, including words longer than two characters potentially *peek* into the QIE compound structure. 

> describe morphological graph. Its vertices, edge number and include a sample figure. what's other index to describe a graph? raidus is hard to compute..!!

> define M-Vector here
To obtain a computaitonal representation of characters in morphological grpah, we employed node2vec() to compute a low-dimensional vector representation for each character. These vectors were called morphological vector (M-Vector) in this papaer.  

node2vec found a mapping $f: V \rightarrow \mathbb{R}^d$ from each vertices to a vector representation, and the mapping was optimized to maximize the log-probability of observing its neighbors in the network given the vector:

$$
\max_{f} \sum_{c\in\mathbb{C}}\log p(N(c)|f(c))
$$

We define $\mu_i = f(c_i)$ as the M-vector of character $i$ in the morphological graph.

$$
p(c_2 \mid c_1) =
    \frac{\exp\left(\phi(\mu_1, \mu_2)\right)}
    {\sum_{j \in \mathbb{C}} \exp\left(\phi(\mu_i, \mu_j)\right)}
$$

where $\phi(x, y)$ is cosine similarities between two vectors.

$$
\mathrm{compoundness} = p(x_1, x_2, x_3, x_4) = \\
p(x_1) p(x_2 \mid x_1)\,p(x_3 \mid x_2)\,p(x_4 \mid x_3)
$$

## Modeling Compositioness

We define $\sigma_i$ as the sense vectors constructed from example sentences in CWN senses. Similarly, for each QIE in the analysis, we constructed $\sigma_q$ from sentences in corpus to construct contextualized embeddings.


$$
\sigma_\mathrm{target} = \mathop{\bm{\mathrm{E}}}_{\mathbf{w}\in\mathbb{W}}\left[\mathrm{CE}(\mathbf{w})\cdot\mathrm{I}_{\mathrm{target}}(\mathbf{w})\right]
$$

However, M-vectors only describe the morphological behaviors of a word in lemma level, while sense vectors operates on sense level. We need a method to project the semantic space into morphological space. Leveragin on the heurisitic that the first sense in CWN are the most frequently used sense, we construct a morphological matrix $\mathbf{M}$, and a first sense matrix $\mathbf{S}$, and compute a linear projection matrix $\mathbf{P}$ between the two spaces.

$$
\mathbf{P} = \left( \mathbf{S}^\intercal \mathbf{S} \right)^{-1}\mathbf{S}\mathbf{M}
$$

$$
\hat{\mu}_{\mathrm{target}} = \mathbf{P} \cdot \sigma_{\mathrm{target}}
$$

We can then use the projection matrix to find a estimated M-vector $\hat{\mu}$ for any given S-vector of senses. Basing on the the compound measure dervied above, the most probabile sense sequence can then be decoded with beam search.

After decoding the most probable sense sequence in QIE, we found four $\sigma_{ij}$, which denotes the sense $j$ of character $i$ that were used to estimate the composite vector of the QIE. Combined with the S-vector of QIE itself, we introduced the compositioness measure:






$$
\mathrm{compositioness} = 
\sqrt{ \sum_{i \in \mathrm{QIE}_x} 
\left( \sigma_{ij} - \sigma_\mathrm{QIE_x} \right) ^ 2}
$$

# Experiments

## Idiom classification
model hyperparameters tuning 

## Pragmatic synsets in CWN
